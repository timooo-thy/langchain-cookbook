{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is a surname of English origin. It is derived from the Old English words \"lang,\" meaning long, and \"smith,\" meaning someone who works with metal. This surname was likely given to someone who was a blacksmith or who worked with metal in some way.')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is langsmith?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Prompt template with HumanMessage and AIMessage\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessage(content=\"What is langchain?\"),\n",
    "    AIMessage(content=\"Langchain is a platform for building and deploying language models.\"),\n",
    "    HumanMessage(content=\"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I\\'m sorry, but I do not have any additional information on \"langchain\" as it appears to be a made-up term or a very niche topic with limited publicly available information. If you have more context or details about what you are referring to, I would be happy to try to provide more assistance.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke({\"input\":\"Tell me more about it.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# String output parser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain is a decentralized blockchain-based platform that aims to revolutionize the language industry by providing a secure and transparent ecosystem for language learning, translation, and communication. It leverages blockchain technology to create a decentralized marketplace where users can buy and sell language-related services, such as translation, interpretation, and language tutoring, without the need for intermediaries. The platform also features a token economy that incentivizes users to contribute to the community and rewards them for their participation. Overall, Langchain aims to make language learning and communication more accessible, efficient, and secure for people around the world.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain with prompt, llm and output_parser\n",
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"input\":\"Tell me more about it.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have any specific information on \"langchain\" as it seems to be a relatively unknown term or concept. If you have any further context or details about what you are referring to, I would be happy to try to provide more information or assistance."
     ]
    }
   ],
   "source": [
    "# Streaming output\n",
    "for chunk in chain.stream({\"input\":\"Tell me more about it.\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "                                          <context>\n",
    "                                          {context}\n",
    "                                          </context>\n",
    "                                          Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "# Retrieve k relevant documents\n",
    "retriever = vector.as_retriever(search_kwargs={\"k\": 2})\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain is a library available in both Python and JavaScript that provides documentation for the core APIs of LangChain. It appears to be a tool for language processing and manipulation.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Tell me more about langchain?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith'}),\n",
       " Document(page_content='stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting:', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n",
    "    AIMessage(content=\"Yes\")\n",
    "]\n",
    "retriever_chain.invoke({\"chat_history\": chat_history, \"input\": \"Tell me step by step.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is a step-by-step guide to use LangSmith for testing your LLM applications:\n",
      "\n",
      "1. Setup:\n",
      "   - Learn how to create an account on LangSmith.\n",
      "   - Obtain an API key for accessing LangSmith's services.\n",
      "   - Configure your environment to integrate with LangSmith.\n",
      "\n",
      "2. Pricing:\n",
      "   - Understand the pricing model for using LangSmith's testing services.\n",
      "\n",
      "3. Self-Hosting:\n",
      "   - Explore the option of self-hosting LangSmith for testing your LLM applications on your own infrastructure.\n",
      "\n",
      "By following these steps, you can effectively utilize LangSmith for testing your LLM applications.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the following question based only on the provided context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)\n",
    "response = retrieval_chain.invoke({\"chat_history\": chat_history, \"input\": \"Tell me step by step.\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retreiver_tool = create_retriever_tool(retriever, \"langsmith_search\", \"Search for information relevant to Langsmith. For any questions about LangSmith, you must use this tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retreiver_tool, search]\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'What can LangSmith help with testing?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Get started with the evaluation quick start.Next Stepsâ€‹Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing by supporting workflows at each stage of the LLM (Language Model Lifecycle). You can learn more about the specific workflows and how LangSmith can assist in the User Guide.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What can langsmith help with testing?',\n",
       " 'output': 'LangSmith can help with testing by supporting workflows at each stage of the LLM (Language Model Lifecycle). You can learn more about the specific workflows and how LangSmith can assist in the User Guide.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in Singapore today'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"Weather in Singapore is {'location': {'name': 'Singapore', 'region': '', 'country': 'Singapore', 'lat': 1.29, 'lon': 103.86, 'tz_id': 'Asia/Singapore', 'localtime_epoch': 1708789633, 'localtime': '2024-02-24 23:47'}, 'current': {'last_updated_epoch': 1708789500, 'last_updated': '2024-02-24 23:45', 'temp_c': 27.0, 'temp_f': 80.6, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 3.8, 'wind_kph': 6.1, 'wind_degree': 330, 'wind_dir': 'NNW', 'pressure_mb': 1013.0, 'pressure_in': 29.91, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 79, 'cloud': 75, 'feelslike_c': 30.3, 'feelslike_f': 86.5, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 1.0, 'gust_mph': 19.7, 'gust_kph': 31.6}}\"}, {'url': 'https://weatherspark.com/h/y/114655/2024/Historical-Weather-during-2024-in-Singapore', 'content': 'Singapore Temperature History 2024\\nHourly Temperature in 2024 in Singapore\\nCompare Singapore to another city:\\nCloud Cover in 2024 in Singapore\\nObserved Weather in 2024 in Singapore\\nHours of Daylight and Twilight in 2024 in Singapore\\nSunrise & Sunset with Twilight in 2024 in Singapore\\nSolar Elevation and Azimuth in 2024 in Singapore\\nMoon Rise, Set & Phases in 2024 in Singapore\\nHumidity Comfort Levels in 2024 in Singapore\\nWind Speed in 2024 in Singapore\\nHourly Wind Speed in 2024 in Singapore\\nHourly Wind Direction in 2024 in Singapore\\nAtmospheric Pressure in 2024 in Singapore\\nData Sources\\n 81Â°F\\nPrecipitation\\nNo Report\\nWind\\n5.8 mph\\nCloud Cover\\nMostly Cloudy\\n28,000 ft\\nRaw: WSSS 140030Z 34005KT 9999 FEW016 SCT160 BKN280 27/24 Q1011 NOSIG\\n While having the tremendous advantages of temporal and spatial completeness, these reconstructions: (1) are based on computer models that may have model-based errors, (2) are coarsely sampled on a 50 km grid and are therefore unable to reconstruct the local variations of many microclimates, and (3) have particular difficulty with the weather in some coastal areas, especially small islands.\\n We further caution that our travel scores are only as good as the data that underpin them, that weather conditions at any given location and time are unpredictable and variable, and that the definition of the scores reflects a particular set of preferences that may not agree with those of any particular reader.\\n See all nearby weather stations\\nLatest Report â€” 8:30 AM\\nSun, Jan 14, 2024\\xa0\\xa0\\xa0\\xa023 min ago\\xa0\\xa0\\xa0\\xa0UTC 00:30\\nCall Sign WSSS\\nTemp.\\n'}, {'url': 'https://www.weather2travel.com/singapore/february/', 'content': 'Check more long-term weather averages for Singapore in February before you book your next holiday to Singapore in 2024/2025. 30. 30Â°C max day temperature. 7. 7 hours of sunshine per day. 10. 10 days with some rainfall. 23. 23Â°C min night temperature.'}, {'url': 'https://www.whereandwhen.net/when/southeast-asia/singapore/singapore/february/', 'content': \"Average weather throughout february\\ntolerable weather\\nUV index: 7\\nPartly Cloudy41% of time\\n41%\\n20%\\n20%\\n12%\\nModerate rain at times39% of time\\n39%\\n23%\\n19%\\n18%\\nModerate rain at times42% of time\\n42%\\n31%\\n17%\\n10%\\n42%\\n21%\\n20%\\n12%\\nEvolution of daily average temperature and precipitation in Singapore in february\\n Find a flight to Singapore:\\nFind the best price for your hotel room\\nFind the best price for your car rental\\nSearch for a Flight+Hotel package to Singapore in february\\nSeasonal average climate and temperature of Singapore in february\\nCheck below seasonal norms These statistics are set from the weather statements of the last years of february.\\n How was the weather last february?\\nHere is the day by day recorded weather in Singapore in february 2023:\\nMap: other cities in Singapore in february\\nCities near Singapore:\\nClick over cities on the map for information about the weather in february.\\n And When site:\\nSingapore in february: average Weather, Temperature and Climate\\nYou want to go to Singapore in Singapore in february : check the weather and seasonal norms here.\\n The climate of Singapore in february is tolerable\\nThe month of February is one of the periods when heat, characteristic of Singapore's climate, is relatively acceptable.\"}, {'url': 'https://en.climate-data.org/asia/singapore/singapore/singapore-4766/t/february-2/', 'content': 'Â°C\\n(78.4) Â°F\\n26.2 Â°C\\n(79.2) Â°F\\n26.7 Â°C\\n(80.1) Â°F\\n27.1 Â°C\\n(80.7) Â°F\\n27.4 Â°C\\n(81.2) Â°F\\n27.3 Â°C\\n(81.1) Â°F\\n27 Â°C\\n(80.6) Â°F\\n26.9 Â°C\\n(80.4) Â°F\\n26.9 Â°C\\n(80.4) Â°F\\n26.7 Â°C\\n(80.1) Â°F\\n26.3 Â°C\\n(79.3) Â°F\\n26 Â°C\\n(78.7) Â°F\\n24.3 Â°C\\n(75.8) Â°F\\n24.5 Â°C\\n(76.1) Â°F\\n25 Â°C\\n(76.9) Â°F\\n25.4 Â°C\\n(77.7) Â°F\\n25.7 Â°C\\n(78.3) Â°F\\n25.7 Â°C\\n(78.2) Â°F\\n25.5 Â°C\\n(77.8) Â°F\\n25.4 Â°C\\n(77.7) Â°F\\n25.3 Â°C\\n(77.5) Â°F\\n25.1 Â°C\\n(77.1) Â°F\\n24.8 Â°C\\n(76.7) Â°F\\n24.6 Â°C\\n(76.3) Â°F\\n27.9 Â°C\\n(82.2) Â°F\\n28.7 Â°C\\n(83.6) Â°F\\n29.1 Â°C\\n(84.4) Â°F\\n29.2 Â°C\\n(84.5) Â°F\\n29.1 Â°C\\n(84.4) Â°F\\n29 Â°C\\n(84.1) Â°F\\n28.5 Â°C\\n(83.4) Â°F\\n28.5 Â°C\\n(83.2) Â°F\\n28.6 Â°C\\n(83.4) Â°F\\n28.7 Â°C\\n(83.6) Â°F\\n28.3 Â°C\\n(82.9) Â°F\\n28 Â°C\\n(82.4) Â°F\\n168\\n(6)\\n97\\n(3)\\n152\\n(5)\\n198\\n(7)\\n232\\n(9)\\n200\\n(7)\\n199\\n(7)\\n185\\n(7)\\n164\\n(6)\\n214\\n(8)\\n280\\n(11)\\n277\\n(10)\\nData: 1991 - 2021 Min. Temperature Â°C (Â°F), Max. Here you can find all information about the weather in Singapore in February:\\nSingapore weather in February\\nSingapore weather by month // weather averages\\n25.8\\n(78.4)\\n24.3\\n(75.8)\\n27.9\\n(82.2)\\n168\\n(6.6)\\n26.2\\n(79.2)\\n24.5\\n(76.1)\\n28.7\\n(83.6)\\n97\\n(3.8)\\n26.7\\n(80.1)\\n25\\n(76.9)\\n29.1\\n(84.4)\\n152\\n(6)\\n27.1\\n(80.7)\\n25.4\\n(77.7)\\n29.2\\n(84.5)\\n198\\n(7.8)\\n27.4\\n(81.2)\\n25.7\\n(78.3)\\n29.1\\n(84.4)\\n232\\n(9.1)\\n27.3\\n(81.1)\\n25.7\\n(78.2)\\n29\\n(84.1)\\n200\\n(7.9)\\n27\\n(80.6)\\n25.5\\n(77.8)\\n28.5\\n(83.4)\\n199\\n(7.8)\\n26.9\\n(80.4)\\n25.4\\n(77.7)\\n28.5\\n(83.2)\\n185\\n(7.3)\\n26.9\\n(80.4)\\n25.3\\n(77.5)\\n28.6\\n(83.4)\\n164\\n(6.5)\\n26.7\\n(80.1)\\n25.1\\n(77.1)\\n28.7\\n(83.6)\\n214\\n(8.4)\\n26.3\\n(79.3)\\n24.8\\n(76.7)\\n28.3\\n(82.9)\\n280\\n(11)\\n26\\n(78.7)\\n24.6\\n(76.3)\\n28\\n(82.4)\\n277\\n(10.9)\\n25.8 London (LHR), Copenhagen (CPH), Sydney (SYD), Mumbai (BOM), New Delhi (DEL), Paris (CDG), Beijing (PEK), Yangon (RGN), Frankfurt am Main (FRA), Tashkent (TAS), Perth (PER), Dubai (DXB), Colombo (CMB), Osaka (KIX), Kaohsiung City (KHH), Milan (MXP), Kathmandu (KTM), Rome (FCO), Hanoi (HAN), Gold Coast (OOL)\\nBarcelona (BCN), Chiang Mai (CNX), Manila (MNL), Kalibo (KLO), Port Moresby (POM), Zurich (ZRH), Chengdu (CTU), Fuzhou (FOC), Guiyang (KWE), Guangzhou (CAN), Haikou (HAK), Hangzhou (HGH), Ningbo (NGB), Nanjing (NKG), Qingdao (TAO), Shantou (SWA), Tianjin (TSN), Xiamen (XMN), Wuhan (WUH), Thiruvananthapuram (TRV), Coimbatore (CJB), Hyderabad (HYD), Visakhapatnam (VTZ), Kolkata (CCU), Ahmedabad (AMD), Phuket (HKT), Siem Reap (REP), Abu Dhabi (AUH), Tokyo (NRT), Amsterdam (AMS), Auckland (AKL), Ipoh (IPH), Hat Yai (HDY), Kota Kinabalu (BKI), Riyadh (RUH), Davao City (DVO), Pekanbaru (PKU), Ho Chi Minh City (SGN), Da Nang (DAD), Mataram (LOP), Bengaluru (BLR), Nanning (NNG), Lapu-Lapu City (CEB), Phnom Penh (PNH), Tokoname (NGO), Christchurch (CHC), Kuching (KCH), Kuantan (KUA), Chongqing (CKG), Shanghai (PVG), Adelaide (ADL), Taipei City (TPE), Helsinki (HEL), Brisbane (BNE), Bangkok (DMK), Darwin (DRW), Doha (DOH), Moscow (DME), Bandar Seri Begawan (BWN), Munich (MUC), Iloilo City (ILO), Miri (MYY), Kuala Terengganu (TGG), Lijiang (LJG), Krabi (KBV), Penang (PEN), Ko Samui (USM), Jakarta (CGK), Istanbul (IST), Kuala Lumpur (KUL), Seoul (ICN), Melbourne (MEL), Subang (SZB), Jeddah (JED), Changsha (CSX), Fukuoka (FUK), Taipa (MFM), Cochin (COK), Kunming (KMG), Surabaya (SUB), Hong Kong (HKG), Wuxi (WUX), Chennai (MAA), Dhaka (DAC), Shenzhen (SZX)\\nLondonSydneyMelbourneTorontoDubaiNew YorkVancouverParisLas VegasLos Angeles\\nOrlando in JanuaryNashville in JanuaryLas Vegas in JanuaryNew York in JanuaryCalifornia in JanuaryAustin in JanuaryTenerife in JanuaryBenidorm in JanuaryMelbourne in JanuaryNew Delhi in JanuaryManali in January\\nNew Orleans in FebruaryOrlando in FebruaryLas Vegas in FebruaryNashville in FebruaryPalm Springs in FebruaryPhoenix in FebruaryMelbourne in FebruaryTenerife in FebruaryAlgarve in FebruaryNew Delhi in FebruaryManali in February\\nLas Vegas in DecemberOrlando in DecemberLas Vegas in MarchOrlando in JanuaryNashville in DecemberTurkey in SeptemberTurkey in JuneBenidorm in AprilManali in DecemberMelbourne in DecemberSydney in DecemberNew York in December\\nTiban IndahTanjung UmaDanga BayTasek UtaraJohor Bahru CentralPelangiPasir GudangTanjung LangsatLarkinJohor BahruPermas JayaMasaiSeri AlamKota MasaiLubuk BajaSungai JodohSungai JodohBatam CityTanjung PinangLadang Sun hours\\nSingapore weather and climate for further months\\nSingapore weather in February // weather averages\\nAirport close to Singapore\\nThe closest Airports of Singapore are: Changi Air Base (SIN) 17.23km\\nYou can reach Singapore from this Cities by Plane: Temperature Â°C (Â°F), Precipitation / Rainfall mm (in), Humidity, Rainy days.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in Singapore today is partly cloudy with a temperature of 27.0Â°C (80.6Â°F). The wind speed is 3.8 mph and the humidity is 79%. It is currently nighttime in Singapore.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the weather like today in singapore ?',\n",
       " 'output': 'The weather in Singapore today is partly cloudy with a temperature of 27.0Â°C (80.6Â°F). The wind speed is 3.8 mph and the humidity is 79%. It is currently nighttime in Singapore.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is the weather like today in singapore ?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TypeScript is a programming language developed by Microsoft that is a superset of JavaScript. It adds static typing to the language, making it easier to catch errors and bugs in the code during development. TypeScript also includes features such as interfaces, classes, and modules, which help organize and structure code in a more maintainable way.\\n\\nOne of the main benefits of using TypeScript is that it allows developers to write cleaner and more scalable code, as the type system helps to enforce consistency and reduce the likelihood of runtime errors. Additionally, TypeScript code can be compiled into plain JavaScript, which means it can be run on any browser or platform that supports JavaScript.\\n\\nOverall, TypeScript is a popular choice for developers who want to take advantage of the benefits of static typing while still working within the familiar syntax and ecosystem of JavaScript.'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser, JsonKeyOutputFunctionsParser\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Tell me about {subject}\"\"\")\n",
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"subject\":\"typescript\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"joke\",\n",
    "        \"description\": \"A joke\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"setup\": {\"type\": \"string\", \"description\": \"The setup for the joke\"},\n",
    "                \"punchline\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The punchline for the joke\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"setup\", \"punchline\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "chain = prompt | llm.bind(function_call={\"name\":\"joke\"}, functions=functions) | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why did the dog sit in the shade?',\n",
       " 'punchline': \"Because he didn't want to be a hot dog!\"}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"subject\":\"joke about dog\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Because he had perfect pitch!'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm.bind(function_call={\"name\":\"joke\"}, functions=functions) | JsonKeyOutputFunctionsParser(key_name=\"punchline\")\n",
    "chain.invoke({\"subject\":\"joke about dog\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = {\"subject\": RunnablePassthrough()} | prompt | llm.bind(function_call={\"name\":\"joke\"}, functions=functions) | JsonKeyOutputFunctionsParser(key_name=\"punchline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He wanted a well-balanced meal!'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Singapore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with Qdrant Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "from qdrant_client.http import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://d57352dd-722d-437b-8250-674f0ba883f3.us-east4-0.gcp.cloud.qdrant.io:6333'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"QDRANT_HOST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(os.getenv(\"QDRANT_HOST\"), api_key=os.getenv(\"QDRANT_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_config = models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    "# create collection\n",
    "client.recreate_collection(collection_name=\"langsmith_cookbook\", vectors_config=vectors_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "vector = Qdrant(client, \"langsmith_cookbook\", embeddings=embeddings)\n",
    "retriever = vector.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03e55596c9b641a7a30184147dd870f4',\n",
       " 'f1ae83fc93284b928055dc53e22ceef4',\n",
       " '59e483e9e6254d538b8007a5866c7fda',\n",
       " '1a75cac9a17e4a579684cb6e62250b05',\n",
       " '7aa9b47010ed4a1fb4099063bd9bbf12',\n",
       " '47e652c6a91742c18003bf0e7ef7659b',\n",
       " 'd0c905a7440a4aafad146759ca5b0e34',\n",
       " '3a9a9fc9126649f58c0344360538a799',\n",
       " '2f9ac9a9637e4228862d66ab36e7ebe9',\n",
       " 'd5d78a760d1943e9bbe39775f6b2c74a',\n",
       " 'd387a07d0ed74c3e83c5dd2605cae0c4',\n",
       " 'd10fcf8fa3994ebb97ccad440f9cc302',\n",
       " '7aaeb53d78794b1d9f274b3de32f0679',\n",
       " '62c8cff3524e4b9799db4e384f7402f3']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.text import TextLoader\n",
    "loader = TextLoader(\"./langchain_docs.txt\")\n",
    "document = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(document)\n",
    "vector.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "                                          <context>\n",
    "                                          {context}\n",
    "                                          </context>\n",
    "                                          Question: {input}\"\"\")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\": \"What link to find for langchain quickstart?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The link to find for LangChain quickstart is: https://python.langchain.com/docs/get_started/quickstart'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
